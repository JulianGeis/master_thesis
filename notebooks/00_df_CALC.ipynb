{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Notebook to calculate all important metrics for the networks and save them"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pypsa\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# imported own functions\n",
    "from utils import market_values, capacity, generation\n",
    "from utils import generation_storage_units, consumption_storage_units, capacity_storage_units, capacity_storage_units_con, market_values_storage_units, market_values_storage_units_con\n",
    "from utils import generation_links, generation_links_bus, capacity_links, capacity_links_bus, market_values_links, market_values_links_bus\n",
    "\n",
    "# imported own definitions\n",
    "from utils import resistive_heater, gas_boiler, heat_pump, water_tanks_charger, water_tanks_discharger, solar_thermal, nodal_balance\n",
    "\n",
    "# general variables\n",
    "onshore_regions = gpd.read_file(\"../data/external/regions_onshore_elec_s_181.geojson\")\n",
    "offshore_regions = gpd.read_file(\"../data/external/regions_offshore_elec_s_181.geojson\")\n",
    "onshore_regions = onshore_regions.set_index('name')\n",
    "offshore_regions = offshore_regions.set_index('name')\n",
    "\n",
    "# Regions\n",
    "onshore_regions['coords'] = onshore_regions['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "onshore_regions['coords'] = [coords[0] for coords in onshore_regions['coords']]\n",
    "onshore_regions[\"name\"] = onshore_regions.index\n",
    "offshore_regions['coords'] = offshore_regions['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "offshore_regions['coords'] = [coords[0] for coords in offshore_regions['coords']]\n",
    "offshore_regions[\"name\"] = offshore_regions.index\n",
    "\n",
    "# carrier lists\n",
    "from utils import c_el_gen_s, c_el_con_s, c_h2_gen, c_h2_con\n",
    "\n",
    "# Notebook Definitions\n",
    "c1_groups = [resistive_heater, gas_boiler, heat_pump, water_tanks_charger, water_tanks_discharger, solar_thermal]\n",
    "c1_groups_name = [\"resistive heater\", \"gas boiler\", \"heat pump\", \"water tanks charger\", \"water tanks discharger\",\n",
    "                  \"solar thermal\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Network imports\n",
    "stst = pypsa.Network(\"../data/raw/elec_s_181_lv1.0__Co2L0-3H-T-H-B-I-A-solar+p3-linemaxext10-noH2network_2030.nc\")\n",
    "exp = pypsa.Network(\"../data/raw/elec_s_181_lvopt__Co2L0-3H-T-H-B-I-A-solar+p3-linemaxext10_2030.nc\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spatial dfs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### old CALC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calc market values, generation, lmps, capacity factors for generators, links and storage units\n",
    "for n in [stst, exp]:\n",
    "    df_regions_onshore = onshore_regions.copy()\n",
    "    df_regions_offshore = offshore_regions.copy()\n",
    "\n",
    "    # function for carriers in n.generators.carrier.unique() # 13 / 13\n",
    "    for carrier in n.generators.carrier.unique():\n",
    "        df_regions_onshore[f\"{carrier}_mv\"] = market_values(n, carrier)\n",
    "        df_regions_offshore[f\"{carrier}_mv\"] = market_values(n, carrier)\n",
    "        df_regions_onshore[f\"{carrier}_gen\"] = generation(n, carrier) / 1000 * 3\n",
    "        df_regions_offshore[f\"{carrier}_gen\"] = generation(n, carrier) / 1000 * 3\n",
    "        df_regions_onshore[f\"{carrier}_cap\"] = capacity(n, carrier) / 1000\n",
    "        df_regions_offshore[f\"{carrier}_cap\"] = capacity(n, carrier) / 1000\n",
    "        # lmps\n",
    "        # capacity factors This calculation is correct? as capacity is multiplied by 2920 is the same as multiplying the generation by 3 and then dividing it by the capacity times 8760 (as cap is in MW?)\n",
    "        df_regions_onshore[f\"{carrier}_cf\"] = generation(n, carrier) / (capacity(n, carrier) * 2920)\n",
    "        df_regions_offshore[f\"{carrier}_cf\"] = generation(n, carrier) / (capacity(n, carrier) * 2920)\n",
    "\n",
    "    # function for carriers in n.links.carrier.unique() # 53 / 55\n",
    "    for carrier in n.links.carrier.unique():\n",
    "        df_regions_onshore[f\"{carrier}_mv\"] = market_values_links(n, carrier)\n",
    "        df_regions_onshore[f\"{carrier}_gen\"] = generation_links(n, carrier) / 1000 * 3\n",
    "        df_regions_onshore[f\"{carrier}_cap\"] = capacity_links(n, carrier) / 1000\n",
    "        df_regions_onshore[f\"{carrier}_cf\"] = generation_links(n, carrier) / (capacity_links(n, carrier) * 2920)\n",
    "\n",
    "    # function for carriers in n.storage_units.carrier.unique() # 2 / 2\n",
    "    for carrier in n.storage_units.carrier.unique():\n",
    "        df_regions_onshore[f\"{carrier}_mv\"] = market_values_storage_units(n, carrier)\n",
    "        df_regions_onshore[f\"{carrier}_gen\"] = generation_storage_units(n, carrier) / 1000 * 3\n",
    "        df_regions_onshore[f\"{carrier}_cap\"] = capacity_storage_units(n, carrier) / 1000\n",
    "        # capacity factors (both generation and consumption(loading) is considered\n",
    "        gen = abs(n.storage_units_t.p.loc[:, n.storage_units.carrier == carrier])\n",
    "        gen.columns = gen.columns.map(n.storage_units.bus)\n",
    "        gen.columns = gen.columns.map(n.buses.location)\n",
    "        df_regions_onshore[f\"{carrier}_cf\"] = gen.sum() / (2*capacity_storage_units(n, carrier) * 2920)\n",
    "\n",
    "    # set market values to nan where generation in corresponding region is lower than % quantile ( for generators, links, su)\n",
    "    qt = 0.2\n",
    "    for carrier in (n.generators.carrier.unique().tolist() +\n",
    "                    n.links.carrier.unique().tolist() +\n",
    "                    n.storage_units.carrier.unique().tolist()):\n",
    "        # onshore\n",
    "        index = df_regions_onshore[f\"{carrier}_gen\"] <= np.nanquantile(df_regions_onshore[f\"{carrier}_gen\"], qt)\n",
    "        df_regions_onshore[f\"{carrier}_mv_qt\"] = df_regions_onshore[f\"{carrier}_mv\"]\n",
    "        df_regions_onshore[f\"{carrier}_mv_qt\"][index] = np.nan\n",
    "\n",
    "        # offshore\n",
    "        if carrier in [\"offwind-dc\", \"offwind-ac\"]:\n",
    "            index = df_regions_offshore[f\"{carrier}_gen\"] <= np.nanquantile(df_regions_offshore[f\"{carrier}_gen\"], qt)\n",
    "            df_regions_offshore[f\"{carrier}_mv_qt\"] = df_regions_offshore[f\"{carrier}_mv\"]\n",
    "            df_regions_offshore[f\"{carrier}_mv_qt\"][index] = np.nan\n",
    "\n",
    "    # calc lmps at the buses (lmps that are only present for EU (e.g. oil) are nan at the moment)\n",
    "    # TODO: decide if EU lmps are used as lmp for all regions\n",
    "    for carrier_bus in n.buses.carrier.unique():\n",
    "        # index would be same names as the bus (not the location as it is in the index of\n",
    "        # df_regions_onshore so far -> map location to make sure the right lmp is set\n",
    "        locs = n.buses.location[n.buses[n.buses.carrier == carrier_bus].index]\n",
    "        # simple mean of lmps\n",
    "        lmps = n.buses_t.marginal_price[n.buses[n.buses.carrier == carrier_bus].index].mean()\n",
    "        df = pd.concat([lmps, locs], axis=1).rename(columns={0: f\"{carrier_bus}_lmp\"})\n",
    "        df.set_index(\"location\", inplace=True)\n",
    "        if df.size == 1:\n",
    "            if df.index == \"EU\":\n",
    "                df = pd.DataFrame(np.repeat(df.values, 181), index=df_regions_onshore.index,\n",
    "                                  columns=[f\"{carrier_bus}_lmp\"])\n",
    "                df_regions_onshore[f\"{carrier_bus}_lmp\"] = df[f\"{carrier_bus}_lmp\"]\n",
    "        else:\n",
    "            df_regions_onshore[f\"{carrier_bus}_lmp\"] = df[f\"{carrier_bus}_lmp\"]\n",
    "\n",
    "    if n == stst:\n",
    "        df_stst_ons = df_regions_onshore\n",
    "        df_stst_off = df_regions_offshore\n",
    "\n",
    "    if n == exp:\n",
    "        df_exp_ons = df_regions_onshore\n",
    "        df_exp_off = df_regions_offshore"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# subdivide all carriers: stst.buses.carrier.unique().tolist()\n",
    "\n",
    "electricity = ['AC', 'battery', 'Li ion', 'low voltage', 'home battery' ]\n",
    "hydrogen = ['H2', 'H2 liquid']\n",
    "heat = ['residential rural heat',\n",
    " 'residential rural water tanks',\n",
    " 'services rural heat',\n",
    " 'services rural water tanks',\n",
    " 'residential urban decentral heat',\n",
    " 'residential urban decentral water tanks',\n",
    " 'services urban decentral heat',\n",
    " 'services urban decentral water tanks',\n",
    " 'urban central heat',\n",
    " 'urban central water tanks']\n",
    "gas = ['gas', 'biogas', 'gas for industry']\n",
    "oil = ['oil']\n",
    "biomass = ['solid biomass','solid biomass for industry']\n",
    "co2 = ['co2','co2 stored']\n",
    "process_emisisons = ['process emissions']\n",
    "\n",
    "c_tags = {\n",
    "    'AC': \"el\",\n",
    "    'battery': \"el\",\n",
    "    'Li ion': \"el\",\n",
    "    'low voltage': \"el\",\n",
    "    'home battery': \"el\",\n",
    "    'H2': \"h2\",\n",
    "    'H2 liquid': \"h2\",\n",
    "    'residential rural heat': \"heat\",\n",
    "    'residential rural water tanks': \"heat\",\n",
    "    'services rural heat': \"heat\",\n",
    "    'services rural water tanks': \"heat\",\n",
    "    'residential urban decentral heat': \"heat\",\n",
    "    'residential urban decentral water tanks': \"heat\",\n",
    "    'services urban decentral heat': \"heat\",\n",
    "    'services urban decentral water tanks': \"heat\",\n",
    "    'urban central heat': \"heat\",\n",
    "    'urban central water tanks': \"heat\",\n",
    "    'gas': \"gas\",\n",
    "    'biogas': \"gas\",\n",
    "    'gas for industry': \"gas\",\n",
    "    'oil': \"oil\",\n",
    "    'solid biomass': \"biom\",\n",
    "    'solid biomass for industry': \"biom\",\n",
    "    'co2': \"co2\",\n",
    "    'co2 stored': \"co2\",\n",
    "    'process emissions': \"pe\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### new CALC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calc demand weighted lmps for selected buses\n",
    "\n",
    "dw_lmp_buses = [\"AC\", \"low voltage\", \"H2\"]\n",
    "\n",
    "for n, dfs in zip([stst, exp], [df_stst_ons,df_exp_ons]):\n",
    "    for c in dw_lmp_buses:\n",
    "\n",
    "        # demand weighted lmp per region\n",
    "        nb = nodal_balance(n, carrier=c, time=\"2013\", aggregate=['component'], energy=True)\n",
    "        nb = nb.unstack(level=[1])\n",
    "        weights = nb[nb < 0].groupby(by=\"snapshot\").sum().abs()\n",
    "        lmps = n.buses_t.marginal_price.loc[:, n.buses.carrier == c]\n",
    "        dw_lmps = np.multiply(lmps, weights / weights.sum()).sum()\n",
    "        dw_lmps.index = dw_lmps.index.map(n.buses.location)\n",
    "        dfs[f\"{c}_dw_lmp\"] = dw_lmps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df_stst_ons, df_stst_off, df_exp_ons, df_exp_off\n",
    "# conventions: consumption is negative, values in GW, GWh\n",
    "# subdivide gen, mv, cap and cf into electricity, heat, hydrogen, .\n",
    "\n",
    "buses = [\"bus0\", \"bus1\", \"bus2\", \"bus3\", \"bus4\"]\n",
    "ps = [\"p0\", \"p1\", \"p2\", \"p3\", \"p4\"]\n",
    "\n",
    "for n, dfs in zip([stst, exp], [[df_stst_ons, df_stst_off], [df_exp_ons, df_exp_off]]):\n",
    "\n",
    "    # generators: can only generate energy, have only one bus, have only one capacity, can have only one carrier\n",
    "    for c in n.generators.carrier.unique().tolist():\n",
    "        # get tag\n",
    "        c_bus = n.generators[n.generators.carrier == c].bus.map(n.buses.carrier).unique()[0]\n",
    "        c_tag = c_tags[c_bus]\n",
    "        for df in dfs:\n",
    "            df[f\"{c}_gen_{c_tag}\"] = generation(n, c) / 1000 * 3\n",
    "            df[f\"{c}_cap_gen_{c_tag}\"] = capacity(n, c) / 1000\n",
    "            df[f\"{c}_mv_gen_{c_tag}\"] = market_values(n, c)\n",
    "            df[f\"{c}_cf_gen_{c_tag}\"] = generation(n, c) / (capacity(n, c) * 2920)\n",
    "            # only for onshore\n",
    "            if len(df) != 100:\n",
    "                df[f\"{c}_mv-lmp_gen_{c_tag}\"] = df[f\"{c}_mv_gen_{c_tag}\"] - df[f\"{c_bus}_lmp\"]\n",
    "                df[f\"{c}_vf_gen_{c_tag}\"] = df[f\"{c}_mv_gen_{c_tag}\"] / df[f\"{c_bus}_lmp\"]\n",
    "                # calc demand weighted value factor for selected buses\n",
    "                if c_bus in dw_lmp_buses:\n",
    "                    df[f\"{c}_vf_dw_gen_{c_tag}\"] = df[f\"{c}_mv_gen_{c_tag}\"] / df[f\"{c_bus}_dw_lmp\"]\n",
    "\n",
    "\n",
    "    # storage units: can generate and consume, have only one bus, have twoe capacities?, can have only one carrier\n",
    "    for c in n.storage_units.carrier.unique().tolist():\n",
    "        # get tag\n",
    "        c_bus = n.storage_units[n.storage_units.carrier == c].bus.map(n.buses.carrier).unique()[0]\n",
    "        c_tag = c_tags[c_bus]\n",
    "        for df in dfs:\n",
    "            df[f\"{c}_gen_{c_tag}\"] = generation_storage_units(n, c) / 1000 * 3\n",
    "            df[f\"{c}_con_{c_tag}\"] = consumption_storage_units(n, c) / 1000 * 3\n",
    "            df[f\"{c}_cap_gen_{c_tag}\"] = capacity_storage_units(n, c) / 1000\n",
    "            df[f\"{c}_cap_con_{c_tag}\"] = capacity_storage_units_con(n, c) / 1000\n",
    "            df[f\"{c}_mv_gen_{c_tag}\"] = market_values_storage_units(n, c)\n",
    "            df[f\"{c}_mv_con_{c_tag}\"] = market_values_storage_units_con(n, c)\n",
    "            df[f\"{c}_cf_gen_{c_tag}\"] = generation_storage_units(n, c) / (capacity_storage_units(n, c) * 2920)\n",
    "            df[f\"{c}_cf_con_{c_tag}\"] = consumption_storage_units(n, c) / (capacity_storage_units(n, c) * 2920)\n",
    "            # capacity factor of consumption and generation\n",
    "            df[f\"{c}_cf_gen+con_{c_tag}\"] = (generation_storage_units(n, c) + consumption_storage_units(n, c)) / ((capacity_storage_units(n, c) + capacity_storage_units_con(n, c)) * 2920)\n",
    "            # only for onshore\n",
    "            if len(df) != 100:\n",
    "                df[f\"{c}_mv-lmp_gen_{c_tag}\"] = df[f\"{c}_mv_gen_{c_tag}\"] - df[f\"{c_bus}_lmp\"]\n",
    "                df[f\"{c}_vf_gen_{c_tag}\"] = df[f\"{c}_mv_gen_{c_tag}\"] / df[f\"{c_bus}_lmp\"]\n",
    "                df[f\"{c}_mv-lmp_con_{c_tag}\"] = df[f\"{c}_mv_con_{c_tag}\"] - df[f\"{c_bus}_lmp\"]\n",
    "                df[f\"{c}_vf_con_{c_tag}\"] = df[f\"{c}_mv_con_{c_tag}\"] / df[f\"{c_bus}_lmp\"]\n",
    "                # calc demand weighted value factor for selected buses\n",
    "                if c_bus in dw_lmp_buses:\n",
    "                    df[f\"{c}_vf_dw_gen_{c_tag}\"] = df[f\"{c}_mv_gen_{c_tag}\"] / df[f\"{c_bus}_dw_lmp\"]\n",
    "                    df[f\"{c}_vf_dw_con_{c_tag}\"] = df[f\"{c}_mv_con_{c_tag}\"] / df[f\"{c_bus}_dw_lmp\"]\n",
    "\n",
    "    # links: can generate and consume, have several buses with different numbers, have several capacities, can have several carriers even per bus (e.g. DAC bus3 generates heat for urban central and urban decentral)\n",
    "    for c in n.links.carrier.unique():\n",
    "        for i, bus in enumerate(buses):\n",
    "            # check if bus exists\n",
    "            if n.links[n.links.carrier == c][bus][0] != \"\":\n",
    "                # tag\n",
    "                c_bus = n.links[n.links.carrier == c][bus].map(n.buses.carrier).unique()[0]\n",
    "                c_tag = c_tags[c_bus]\n",
    "\n",
    "                for df in dfs:\n",
    "                    # check if consumption or generation\n",
    "                    gen = generation_links_bus(n, c, i)\n",
    "                    gen_tag = \"gen\" if gen.sum() > 0 else \"con\"\n",
    "                    df[f\"{c}_{gen_tag}_{c_tag}\"] = gen / 1000 * 3\n",
    "                    df[f\"{c}_cap_{gen_tag}_{c_tag}\"] = capacity_links_bus(n, c, i) / 1000\n",
    "                    df[f\"{c}_cf_{gen_tag}_{c_tag}\"] = abs(gen) / (capacity_links_bus(n, c, i) * 2920)\n",
    "                    df[f\"{c}_mv_{gen_tag}_{c_tag}\"] = market_values_links_bus(n, c, i)\n",
    "                    # only for onshore\n",
    "                    if len(df) != 100:\n",
    "                        df[f\"{c}_mv-lmp_{gen_tag}_{c_tag}\"] = df[f\"{c}_mv_{gen_tag}_{c_tag}\"] - df[f\"{c_bus}_lmp\"]\n",
    "                        df[f\"{c}_vf_{gen_tag}_{c_tag}\"] = df[f\"{c}_mv_{gen_tag}_{c_tag}\"] / df[f\"{c_bus}_lmp\"]\n",
    "                        # calc demand weighted value factor for selected buses\n",
    "                        if c_bus in dw_lmp_buses:\n",
    "                            df[f\"{c}_vf_dw_{gen_tag}_{c_tag}\"] = df[f\"{c}_mv_{gen_tag}_{c_tag}\"] / df[f\"{c_bus}_dw_lmp\"]\n",
    "\n",
    "\n",
    "# set market values to nan where generation / consumption in corresponding region is lower / higher than 20%  / 80 % quantile\n",
    "gen_qt = 0.2\n",
    "con_qt = 0.8\n",
    "\n",
    "for df in [df_stst_ons, df_stst_off, df_exp_ons, df_exp_off]:\n",
    "\n",
    "    # generation\n",
    "    for col in df.columns[df.columns.str.contains(\"mv_gen\")].tolist():\n",
    "        index = df[col.replace(\"mv_\", \"\")] <= np.nanquantile(df[col.replace(\"mv_\", \"\")], gen_qt)\n",
    "        df[f\"{col}_qt\"] = df[col]\n",
    "        df[f\"{col}_qt\"][index] = np.nan\n",
    "\n",
    "    #consumption\n",
    "    for col in df.columns[df.columns.str.contains(\"mv_con\")].tolist():\n",
    "        index = df[col.replace(\"mv_\", \"\")] >= np.nanquantile(df[col.replace(\"mv_\", \"\")], con_qt)\n",
    "        df[f\"{col}_qt\"] = df[col]\n",
    "        df[f\"{col}_qt\"][index] = np.nan\n",
    "\n",
    "    # generation\n",
    "    for col in df.columns[df.columns.str.contains(\"vf_gen\")].tolist():\n",
    "        index = df[col.replace(\"vf_\", \"\")] <= np.nanquantile(df[col.replace(\"vf_\", \"\")], gen_qt)\n",
    "        df[f\"{col}_qt\"] = df[col]\n",
    "        df[f\"{col}_qt\"][index] = np.nan\n",
    "\n",
    "    #consumption\n",
    "    for col in df.columns[df.columns.str.contains(\"vf_con\")].tolist():\n",
    "        index = df[col.replace(\"vf_\", \"\")] >= np.nanquantile(df[col.replace(\"vf_\", \"\")], con_qt)\n",
    "        df[f\"{col}_qt\"] = df[col]\n",
    "        df[f\"{col}_qt\"][index] = np.nan\n",
    "\n",
    "    # generation\n",
    "    for col in df.columns[df.columns.str.contains(\"mv-lmp_gen\")].tolist():\n",
    "        index = df[col.replace(\"mv-lmp_\", \"\")] <= np.nanquantile(df[col.replace(\"mv-lmp_\", \"\")], gen_qt)\n",
    "        df[f\"{col}_qt\"] = df[col]\n",
    "        df[f\"{col}_qt\"][index] = np.nan\n",
    "\n",
    "    #consumption\n",
    "    for col in df.columns[df.columns.str.contains(\"mv-lmp_con\")].tolist():\n",
    "        index = df[col.replace(\"mv-lmp_\", \"\")] >= np.nanquantile(df[col.replace(\"mv-lmp_\", \"\")], con_qt)\n",
    "        df[f\"{col}_qt\"] = df[col]\n",
    "        df[f\"{col}_qt\"][index] = np.nan\n",
    "\n",
    "    # generation\n",
    "    for col in df.columns[df.columns.str.contains(\"vf_dw_gen\")].tolist():\n",
    "        index = df[col.replace(\"vf_dw_\", \"\")] <= np.nanquantile(df[col.replace(\"vf_dw_\", \"\")], gen_qt)\n",
    "        df[f\"{col}_qt\"] = df[col]\n",
    "        df[f\"{col}_qt\"][index] = np.nan\n",
    "\n",
    "    #consumption\n",
    "    for col in df.columns[df.columns.str.contains(\"vf_dw_con\")].tolist():\n",
    "        index = df[col.replace(\"vf_dw_\", \"\")] >= np.nanquantile(df[col.replace(\"vf_dw_\", \"\")], con_qt)\n",
    "        df[f\"{col}_qt\"] = df[col]\n",
    "        df[f\"{col}_qt\"][index] = np.nan"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Consumed electric energy and prices payed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# consumed electric energy and prices payed\n",
    "# AC and low voltage are the main buses for electricity (why the difference?) Investigate in differences in lmps?\n",
    "\n",
    "for n , df in zip([stst, exp], [df_stst_ons, df_exp_ons]):\n",
    "\n",
    "    for c in c_el_con_s:\n",
    "\n",
    "        # links\n",
    "        if c in n.links.carrier.unique().tolist():\n",
    "            # check if bus 0 is AC or low voltage bus\n",
    "            if n.links[n.links.carrier == c].bus0.map(n.buses.carrier).unique() in [\"AC\", \"low voltage\"]:\n",
    "\n",
    "                # consumption of link at bus 0\n",
    "                con = n.links_t.p0.loc[:, n.links.carrier == c]\n",
    "                con.columns = con.columns.map(n.links.bus0)\n",
    "                # save consumption per location to df\n",
    "                con_sum = con.sum()\n",
    "                con_sum.index = con_sum.index.map(n.buses.location)\n",
    "                # convert to TWh and make negative\n",
    "                df[f\"{c}_con_el2\"] = con_sum / 1000 * 3 * -1\n",
    "                # get lmp of buses where the links consumes from\n",
    "                lmp_con = n.buses_t.marginal_price.loc[:, con.columns]\n",
    "                # calculate costs for every time step and location\n",
    "                overall_cost = con * lmp_con\n",
    "                # calc consumption weighted average per location: overall cost per location / overall generation per location\n",
    "                cost_mv = overall_cost.sum() / con.sum()\n",
    "                cost_mv.index = cost_mv.index.map(n.buses.location)\n",
    "                # save cost_mv to df (â‚¬/MWH_el)\n",
    "                df[f\"{c}_cost_mv_el\"] = cost_mv\n",
    "\n",
    "        # storage unit: only PHS can store\n",
    "        elif c in n.storage_units.carrier.unique().tolist():\n",
    "\n",
    "                # consumption of su\n",
    "                con = n.storage_units_t.p_store.loc[:, n.storage_units.carrier == c]\n",
    "                con.columns = con.columns.map(n.storage_units.bus)\n",
    "                # save consumption per location to df in TWh and make negative\n",
    "                df[f\"{c}_con_el2\"] = con.sum() / 1000 * 3 * -1\n",
    "                # get lmp of buses where the su consumes from\n",
    "                lmp_con = n.buses_t.marginal_price.loc[:, con.columns]\n",
    "                # calculate costs for every time step and location\n",
    "                overall_cost = con * lmp_con\n",
    "                # calc consumption weighted average per location: overall cost per location / overall generation per location\n",
    "                cost_mv = overall_cost.sum() / con.sum()\n",
    "                # save cost_mv to df\n",
    "                df[f\"{c}_cost_mv_el\"] = cost_mv\n",
    "\n",
    "        else:\n",
    "            print(f\"{c} not found!\")\n",
    "\n",
    "        # set pries to nan where consumption in corresponding region is lower than % quantile\n",
    "        # watch out for negative values here!!!!\n",
    "        qt = 0.8\n",
    "        index = df[f\"{c}_con_el2\"] >= np.nanquantile(df[f\"{c}_con_el2\"], qt)\n",
    "        df[f\"{c}_cost_mv_el_qt\"] = df[f\"{c}_cost_mv_el\"]\n",
    "        df[f\"{c}_cost_mv_el_qt\"][index] = np.nan"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utilisation rate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# utilisation rate\n",
    "\n",
    "# what you actually want to measure is on how much of possible generation is utilized\n",
    "# utilitazation rate???\n",
    "# Problem if you calc the rate for every time step and location independently and then take the mean, all urs have the same weight. That makes no sense, as at times with almost no generation there is numerical issues with the rate\n",
    "# better calc ur for every region as the ratio of the sum over all gen and the sum over all possible gen (make sure only valid regions make it to the plot, e.g. minimun generation of o,2 quantile)\n",
    "\n",
    "th = 0.01 # MWh\n",
    "method = 1\n",
    "\n",
    "th_p = 0.01 # share of mean generation\n",
    "\n",
    "# how much of the whole possible energy that can be generated is utilized (sum over all time steps and location than take ratio)\n",
    "overall_ur_stst = pd.DataFrame(index=range(1))\n",
    "overall_ur_exp = pd.DataFrame(index=range(1))\n",
    "\n",
    "for n, df, overall_ur in zip([stst, exp], [df_stst_ons, df_exp_ons], [overall_ur_stst, overall_ur_exp]):\n",
    "\n",
    "    # generators\n",
    "    max_out_gen = n.generators_t.p_max_pu * n.generators.p_nom_opt[n.generators_t.p_max_pu.columns]\n",
    "    real_out_gen = n.generators_t.p[n.generators_t.p_max_pu.columns]\n",
    "    out_ratio_gen = (real_out_gen / max_out_gen) [real_out_gen > th]\n",
    "    out_ratio_gen_sum = real_out_gen.sum() / max_out_gen.sum()\n",
    "\n",
    "    # links\n",
    "    # gen\n",
    "    n_links_p1 = n.links_t.p1 *-1\n",
    "    # some links have a static p_max_pu value and some have an alternating (series)\n",
    "    index_series_li = n.links_t.p_max_pu.columns\n",
    "    index_static_li = n.links.index.difference(n.links_t.p_max_pu.columns)\n",
    "\n",
    "    # calculate the possible output for the link for every time step\n",
    "    if method == 1:\n",
    "        # use p_max_pu * p_nom_op\n",
    "        max_output_links_static = n.links.loc[index_static_li].p_max_pu * n.links.loc[index_static_li].p_nom_opt\n",
    "    elif method == 2:\n",
    "        # alternatively use the maximum of the real output and set it as the maximum capacity\n",
    "        max_output_links_static= n_links_p1[index_static_li].max()\n",
    "\n",
    "    # make ts of max_output_links_static\n",
    "    max_output_links_ts_static = n.links_t.p0[index_static_li].copy()\n",
    "    for snap in n.links_t.p0.index:\n",
    "        max_output_links_ts_static.loc[snap] = max_output_links_static[index_static_li]\n",
    "\n",
    "    # calc time series of time dependent p_max_pu links\n",
    "    max_output_links_ts_series = n.links_t.p_max_pu * n.links.p_nom_opt[index_series_li]\n",
    "\n",
    "    # merge static and series values and reorder columns\n",
    "    max_output_links_ts = pd.concat([max_output_links_ts_static, max_output_links_ts_series], axis=1)[n.links_t.p0.columns]\n",
    "\n",
    "    # compare to real output\n",
    "    out_ratio_links = (n_links_p1 / max_output_links_ts) [n_links_p1 > th]\n",
    "    # calc out ratio weighted by generation (sum of all gen / sum of all cap / max_output)\n",
    "    out_ratio_links_sum = n_links_p1.sum() / max_output_links_ts.sum()\n",
    "\n",
    "    # storage units\n",
    "    max_output = n.storage_units.p_max_pu * n.storage_units.p_nom_opt\n",
    "    max_output_ts_su = n.storage_units_t.p.copy()\n",
    "    for snap in n.storage_units_t.p.index:\n",
    "        max_output_ts_su.loc[snap] = max_output[n.storage_units_t.p.columns]\n",
    "    # compare to real output\n",
    "    out_ratio_su = (n.storage_units_t.p_dispatch / max_output_ts_su) [n.storage_units_t.p_dispatch > th]\n",
    "    out_ratio_su_sum = n.storage_units_t.p_dispatch.sum() / max_output_ts_su.sum()\n",
    "\n",
    "    #######\n",
    "    #######\n",
    "\n",
    "    # gens\n",
    "    for carrier in n.generators.carrier.unique():\n",
    "        if carrier in ['gas', 'oil']:\n",
    "            continue\n",
    "        # calc ur as mean of all urs per time and space\n",
    "        index = n.generators[n.generators.carrier == carrier].index\n",
    "        ur = out_ratio_gen[index].mean()\n",
    "        ur.index = ur.index.map(n.generators.bus).map(n.buses.location)\n",
    "        df[f\"{carrier}_ur_mean\"] = ur\n",
    "\n",
    "        # calc ur as ratio of sum of all gen and sum of all output\n",
    "        ur_s = out_ratio_gen_sum[index][real_out_gen[index].sum() > real_out_gen[index].sum().mean() * th_p]\n",
    "        ur_s.index = ur_s.index.map(n.generators.bus).map(n.buses.location)\n",
    "        df[f\"{carrier}_ur\"] = ur_s\n",
    "\n",
    "        # overall ur\n",
    "        overall_ur[f\"{carrier}\"] = real_out_gen[index].sum().sum() / max_out_gen[index].sum().sum()\n",
    "\n",
    "    # links\n",
    "    for carrier in n.links.carrier.unique():\n",
    "        # calc\n",
    "        index = n.links[n.links.carrier == carrier].index\n",
    "        ur = out_ratio_links[index].mean()\n",
    "        ur.index = ur.index.map(n.links.bus1).map(n.buses.location)\n",
    "        # group duplicate index entries\n",
    "        ur = ur.groupby(by=[\"Link\"], axis=\"index\").mean()\n",
    "        df[f\"{carrier}_ur_mean\"] = ur\n",
    "\n",
    "        # calc ur as ratio of sum of all gen and sum of all output\n",
    "        ur_s = out_ratio_links_sum[index][n_links_p1[index].sum() > n_links_p1[index].sum().mean() * th_p]\n",
    "        ur_s.index = ur_s.index.map(n.links.bus1).map(n.buses.location)\n",
    "        # group duplicate index entries\n",
    "        ur_s = ur_s.groupby(by=[\"Link\"], axis=\"index\").mean()\n",
    "        df[f\"{carrier}_ur\"] = ur_s\n",
    "\n",
    "        # overall ur\n",
    "        overall_ur[f\"{carrier}\"] = n_links_p1[index].sum().sum() / max_output_links_ts[index].sum().sum()\n",
    "\n",
    "    # storage units\n",
    "    for carrier in n.storage_units.carrier.unique():\n",
    "        # calc\n",
    "        index = n.storage_units[n.storage_units.carrier == carrier].index\n",
    "        ur = out_ratio_su[index].mean()\n",
    "        ur.index = ur.index.map(n.storage_units.bus).map(n.buses.location)\n",
    "        df[f\"{carrier}_ur_mean\"] = ur\n",
    "\n",
    "        #\n",
    "        ur_s = out_ratio_su_sum[index][n.storage_units_t.p_dispatch[index].sum() > n.storage_units_t.p_dispatch[index].sum().mean() * th_p]\n",
    "        ur_s.index = ur_s.index.map(n.storage_units.bus).map(n.buses.location)\n",
    "        df[f\"{carrier}_ur\"] = ur_s\n",
    "\n",
    "        # overall ur\n",
    "        overall_ur[f\"{carrier}\"] = n.storage_units_t.p_dispatch[index].sum().sum() / max_output_ts_su[index].sum().sum()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_stst_ons.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_stst_off.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_exp_ons.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_exp_off.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to pickle\n",
    "df_stst_ons.to_pickle(\"../data/processed/df_stst_ons.pkl\")\n",
    "df_stst_off.to_pickle(\"../data/processed/df_stst_off.pkl\")\n",
    "df_exp_ons.to_pickle(\"../data/processed/df_exp_ons.pkl\")\n",
    "df_exp_off.to_pickle(\"../data/processed/df_exp_off.pkl\")\n",
    "\n",
    "overall_ur_stst.to_pickle(\"../data/processed/overall_ur_stst.pkl\")\n",
    "overall_ur_exp.to_pickle(\"../data/processed/overall_ur_exp.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# verify reload\n",
    "df_stst_ons = pd.read_pickle(\"../data/processed/df_stst_ons.pkl\")\n",
    "df_stst_off = pd.read_pickle(\"../data/processed/df_stst_off.pkl\")\n",
    "df_exp_ons = pd.read_pickle(\"../data/processed/df_exp_ons.pkl\")\n",
    "df_exp_off = pd.read_pickle(\"../data/processed/df_exp_off.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_stst_ons[\"Fischer-Tropsch_cap_con_h2\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_stst_ons.head().dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_stst_off.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_exp_ons.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_exp_off.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_c = exp.links.carrier.unique().tolist() + exp.generators.carrier.unique().tolist() + exp.storage_units.carrier.unique().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Temporal dfs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calc electricity and hydrogen generation or consumption for every time step\n",
    "\n",
    "df_stst_ts = pd.DataFrame(index=stst.generators_t.p.index)\n",
    "df_exp_ts = pd.DataFrame(index=exp.generators_t.p.index)\n",
    "\n",
    "for n, df in zip([stst, exp],[df_stst_ts, df_exp_ts]):\n",
    "    for c in all_c: #(c_el_gen_s + c_el_con_s + c_h2_gen + c_h2_con):\n",
    "\n",
    "        if c in n.generators.carrier.unique():\n",
    "            c_bus = n.generators[n.generators.carrier == c].bus.map(n.buses.carrier).unique()[0]\n",
    "            c_tag = c_tags[c_bus]\n",
    "            df[f\"{c}_gen_{c_tag}\"] = n.generators_t.p.loc[:, n.generators.carrier == c].sum(axis=1) * 3\n",
    "\n",
    "        elif c in n.links.carrier.unique():\n",
    "\n",
    "            for i, bus in enumerate(buses):\n",
    "                # check if bus exists\n",
    "                if n.links[n.links.carrier == c][bus][0] != \"\":\n",
    "                    # tag\n",
    "                    c_bus = n.links[n.links.carrier == c][bus].map(n.buses.carrier).unique()[0]\n",
    "                    c_tag = c_tags[c_bus]\n",
    "                    # check if consumption or generation\n",
    "                    gen = generation_links_bus(n, c, i)\n",
    "                    gen_tag = \"gen\" if gen.sum() > 0 else \"con\"\n",
    "                    df[f\"{c}_{gen_tag}_{c_tag}\"] = n.links_t[ps[i]].loc[:, n.links.carrier == c].sum(axis=1) * 3 * -1\n",
    "\n",
    "        elif c in n.storage_units.carrier.unique():\n",
    "            c_bus = n.storage_units[n.storage_units.carrier == c].bus.map(n.buses.carrier).unique()[0]\n",
    "            c_tag = c_tags[c_bus]\n",
    "            df[f\"{c}_gen_el\"] = n.storage_units_t.p_dispatch.loc[:, n.storage_units.carrier == c].sum(axis=1) * 3\n",
    "            df[f\"{c}_con_el\"] = n.storage_units_t.p_store.loc[:, n.storage_units.carrier == c].sum(axis=1) * 3 * -1\n",
    "\n",
    "        else:\n",
    "            print(f\"{c} is not a known carrier in {n}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_stst_ts.columns[df_stst_ts.columns.str.contains(\"pipe\")]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_stst_ts.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save to pickle\n",
    "df_stst_ts.to_pickle(\"../data/processed/df_stst_ts.pkl\")\n",
    "df_exp_ts.to_pickle(\"../data/processed/df_exp_ts.pkl\")\n",
    "\n",
    "# verify reload\n",
    "df_stst_ts = pd.read_pickle(\"../data/processed/df_stst_ts.pkl\")\n",
    "df_exp_ts = pd.read_pickle(\"../data/processed/df_exp_ts.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_stst_ts.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_exp_ts.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}